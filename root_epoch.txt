                epoch_save_list = [30, 90]
            else:
                epoch_save_list = []
            # If optimize_computation, set GAN updating frequency to 1/5.
            ssim_log = 0.
            
            interval = self.optimize_computation
            self.logger.debug("GAN training interval N (once every N step) is set to {}!".format(interval))
            
            adding_noise=False
            centroids_list= [torch.tensor(float('nan')) for _ in range(self.num_class)]
            weights_list= [torch.tensor(float('nan')) for _ in range(self.num_class)]
            cluster_variances_list=[torch.tensor(float('nan')) for _ in range(self.num_class)]
            #Main Training
            lambd_start= self.lambd 
            lambd_end=lambd_start*2
            acc_list=[]
            rob_list= []
            for epoch in range(1, self.n_epochs+1):
                ep_start_time = time.time() 
                if epoch > self.warm:
                    self.scheduler_step(epoch)
                    if self.gan_regularizer:
                        self.gan_scheduler_step(epoch)
                
                # if epoch > 0.3*self.n_epochs:
                #     print('start to adding noise')
                #     adding_noise=True


                self.logger.debug("Train in {} style".format(self.scheme))
                # print("adding noise:",adding_noise)
                Z_all = []
                label_all = [] 
                if epoch ==1:
                    random_ini_centers = True
                else: 
                    random_ini_centers = False
                train_loss_list=[]
                f_loss_list= []
                # é‡æ–°åˆå§‹åŒ–å„å®¢æˆ·ç«¯è¿­ä»£å™¨ï¼Œé¿å…æ²¿ç”¨ä¸Šä¸€è½®æœ«å°¾ä½ç½?
                client_iterator_list = []
                for _cid in range(self.num_client):
                    client_iterator_list.append(iter(self.client_dataloader[_cid]))
                model_train_stime= time.time()
                self.pooling = False
                if "pruning" in self.AT_regularization_option and epoch==self.pruning_ep:
                    self.f = self.model_pruning(self.f,ratio=0.05)
                    summary(self.f.cuda(), input_size=(3,32, 32))
                    
                    self.logger.debug('the model is pruned at epoch:%d',epoch)    
                    
                if "epoch" in self.scheme:
                    for batch in range(self.num_batches):

                        # shuffle_client_list = range(self.num_client)
                        for client_id in range(self.num_client):
                            batch_data_read_start_time = time.time()

                            # try:
                            images, labels = next(client_iterator_list[client_id])
                            if images.size(0) != self.batch_size:
                                client_iterator_list[client_id] = iter(self.client_dataloader[client_id])
                                images, labels = next(client_iterator_list[client_id])
                            # except StopIteration:
                            #     client_iterator_list[client_id] = iter(self.client_dataloader[idxs_users[client_id]])
                            #     images, labels = next(client_iterator_list[client_id])

                            batch_data_read_time = time.time() 

                            # Train the AE decoder if self.gan_regularizer is enabled:
                            if self.gan_regularizer and batch % interval == 0:
                                for i in range(self.gan_num_step): #equals 1 or 3 
                                    ssim_log = -self.gan_train_step(images, client_id, loss_type=self.gan_loss_type)  # orig_epoch_gan_train

                            self.optimizer_zero_grad()
                            
                            # Train step (client/server)
                            # print(images.shape)
                            train_loss, f_loss, z_private = self.train_target_step(images, labels, adding_noise,random_ini_centers,centroids_list,weights_list,cluster_variances_list,client_id)
