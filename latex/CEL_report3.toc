\contentsline {section}{\numberline {1}导言：我们要解决什么问题？}{3}{section.1}%
\contentsline {section}{\numberline {2}基本符号与数据结构}{3}{section.2}%
\contentsline {section}{\numberline {3}整体流程概览}{3}{section.3}%
\contentsline {section}{\numberline {4}注意力与门控的作用机理}{4}{section.4}%
\contentsline {subsection}{\numberline {4.1}为什么需要注意力？}{4}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}注意力模块结构}{4}{subsection.4.2}%
\contentsline {paragraph}{第 1 步：规范化。}{5}{section*.3}%
\contentsline {paragraph}{第 2 步：双投影。}{5}{section*.4}%
\contentsline {paragraph}{第 3 步：门控融合。}{5}{section*.5}%
\contentsline {paragraph}{第 4 步：线性汇聚与 softmax。}{5}{section*.6}%
\contentsline {subsection}{\numberline {4.3}为什么门控有效？}{5}{subsection.4.3}%
\contentsline {section}{\numberline {5}从注意力到条件熵惩罚：数学推导}{6}{section.5}%
\contentsline {subsection}{\numberline {5.1}加权均值与加权方差}{6}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}门控函数与阈值}{6}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}梯度如何影响模型？}{6}{subsection.5.3}%
\contentsline {section}{\numberline {6}完整计算示例}{7}{section.6}%
\contentsline {subsection}{\numberline {6.1}数据设定}{7}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}类别 1 的注意力计算}{7}{subsection.6.2}%
\contentsline {paragraph}{1. 规范化。}{7}{section*.7}%
\contentsline {paragraph}{2. 投影与门控。}{7}{section*.8}%
\contentsline {paragraph}{3. softmax 权重。}{8}{section*.9}%
\contentsline {paragraph}{4. 加权均值与方差。}{8}{section*.10}%
\contentsline {paragraph}{5. 门控惩罚。}{8}{section*.11}%
\contentsline {subsection}{\numberline {6.3}类别 2 的计算（概述）}{8}{subsection.6.3}%
\contentsline {section}{\numberline {7}注意力与门控如何协同降低条件熵}{9}{section.7}%
\contentsline {section}{\numberline {8}关键超参数与直觉}{9}{section.8}%
\contentsline {section}{\numberline {9}总结}{9}{section.9}%
