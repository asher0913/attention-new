在这一阶段的工作中，我一直围绕着“如何让条件熵代理更加敏感、更加自适应”这个主题推进。原始的 CEM-main 把类内特征的聚合与判别交到了高斯混合模型手中，它的优势在于经验公式成熟，但同时也注定了模型对不同数据集、不同分布的适应速度会有限。我这段时间投入最大的精力，就是把这套静态的统计方法，替换成了一个可以在线学习的注意力体系。这个方向听起来只是技术细节的迭代，但实际上，它改变的是我们理解条件熵的方式：不再由预先设定好的分布去描述类内差异，而是让网络本身去学习什么样的差异才是“危险的”、什么样的差异可以被容忍。为了说明这个替换过程，我喜欢用“宏观目标”和“微观实现”两个视角来解释，因为这样可以分别回答“为什么要换”和“具体怎么换”的问题。  

如果站在宏观的角度，我做的第一件事就是重新阐释条件熵 surrogate 的角色。原本的 GMM 模块像是一名统计学家，它拿到一组特征后，会先做一些繁琐的预处理，使用 PCA 把维度降下来，再用高斯分布去拟合每一个簇，最后给我们一个关于类内方差的评价。整个过程虽然可以说得通，但过于依赖人工的设定和 CPU 端的运算。在我设想的注意力体系里，条件熵 surrogate 应当退位，把判断交还给深度模型本身。我希望网络能直接在 GPU 上消费原始特征，把那些真正决定隐私风险的差异抽出来。而要做到这一点，我们就必须构建一个层次式的聚合过程，使得同类样本之间可以先互相理解，再共同决定是否输出一个“危险”的信号。这就是我选择 Slot Attention 与 Cross Attention 组合的原因：用 slot 去总结类别内部的共性，再用跨注意力的方式，让每一个样本重新对照这个“共识”。从宏观来看，这个替换意味着模型不需要再借助外部的统计工具，而是把判断条件熵的过程融入了神经网络自身。  

转换到微观的视角，我们可以更具体地描述这个替换带来的工作量。为了让注意力系统顺利接管 GMM 的位置，我在训练流程的每一个关键节点都做了相应的改造。首先，在所有原本调用 GMM 的函数中，我建立了注意力版的接口，使得输入输出保持一致，保证不会对上层逻辑造成破坏。其次，在特征的流动路径上，我让同一类别的样本先汇聚成 slot，再通过跨注意力进行重构，从而输出一个强化后的特征表征。这一步不是简单的替换，而是要确保整个系统能在高维特征上保持稳定，因此我设计了多层的归一化与缩放机制，让注意力的评分不会飙升或塌陷。我还在每一个关键操作后加入了数值检查，防止出现 NaN 或者 Inf，把所有异常拦截在 surrogate 内部。最终，当注意力模块产出类内方差与条件熵指标时，它的接口和之前的 GMM 模块几乎一致，上层训练流程感知到的只是一个新的“自适应代理”。正是有了这样的微观铺垫，我们才敢在实际训练中完全关闭 GMM，让注意力去承担条件熵的全部计算。  

在替换完成之后，我把注意力代理真正投入到完整训练中时，很快意识到仅仅有注意力是不够的。模型在初期会遇到一个很明显的冲突：注意力输出的特征会很强势，它们会迅速覆盖掉原有的表示，而分类器在面对这些突变时往往反应不过来。为了解决这种“注意力太过热情”的问题，我开始研究如何给注意力加上门控，让它在初期更谨慎一些。我参考了 Flamingo 这类跨模态模型的设计，把残差连接改成带权重的形式，让网络自己决定注意力输出应该以多大的比例叠加到原特征上。这个门控机制在宏观层面上的意义显而易见：我们不再是一刀切地使用注意力，而是让注意力成为一个“被邀请的客人”，它可以提出建议，但最终是否采纳由模型自己判断。具体来说，我给注意力残差设置了一个可训练的系数，初始值非常小，意味着刚开始训练时注意力只是轻轻地影响原有特征，当模型逐渐适应以后，它才会逐步放大自己的声音。这是一种非常贴合实际的做法，因为我们希望网络先把基础分类任务学扎实，再慢慢增强对隐私风险的敏感度。  

门控机制不仅仅体现在注意力输出上，它也帮助我重新理解了条件熵 surrogate 的结构。在没有门控时，注意力输出的信息量几乎无上限，很容易导致网络陷入“几何爆炸”的局面，训练几乎无法进行。而有了门控，我们就等于是对注意力施加了一个“心理咨询师”式的约束，让它有机会反思自己的观点是否过于激进。实际效果也验证了这一点：在加入门控之后，分类损失不再频繁地发散，注意力的输出来得更有节奏，模型也能更稳定地收敛。我把这一点看成是微观调整带来的宏观收益，一个看似简单的缩放参数，却重新定义了注意力在整个系统中的地位。  

当然，替换和门控只是这段工作中的一部分。我还花了不少时间确保整个工程的环境干净、可控。在重构过程中，我顺便处理掉了原来困扰我们许久的日志问题，比如 Prec@1 一直固定在 10% 的 bug、训练到一半突然因为可视化崩溃的问题、缺失数据文件导致 demo 运行失败的问题。这些琐碎的修复其实和注意力替换一样重要，因为它们直接决定了实验能否顺利推进。现在我们的训练日志非常清晰，防御指标和分类指标都能顺利记录下来，任何异常都能第一时间发现。这些看似无关紧要的改进，实际上为注意力代理的调试提供了一个干净的舞台。  

说完做了什么，还需要坦诚地陈述当前为止的现状。总体来看，注意力代理的目标已经实现：它能够独立完成条件熵估计，完全不依赖 GMM。更直观的成果是，模型的防御能力明显提高。我们观察到在多个数据集上，注意力代理能够有效压缩类内方差，让攻击者更难恢复原始信息。这说明我们用注意力去判断隐私风险的思路是成立的，它确实学会了那些传统统计方法难以捕捉的模式。但与此同时，我们也看到了它带来的代价：分类准确率暂时没有达到我们预期的水平。在很多实验里，准确率会维持在一个低位徘徊，表明注意力可能过度抑制了特征多样性。换句话说，我们用更强的隐私保护换来了模型识别能力的下降，这是我们必须面对的现实。  

深入分析之后，我们把问题归纳为几条主线。最突出的是参数规模极大。注意力模块在没有任何预处理的情况下直接处理的是非常高维的扁平化特征，尤其是像 VGG 这样的模型，单个特征向量就有几万维。注意力的线性映射在这种维度下会产生庞大的参数矩阵，不仅训练缓慢，而且数值噪声巨大。如果不加以控制，注意力输出基本上就是一团模糊的塑形噪声，分类器根本无从学习。第二个问题是注意力模块自身的训练策略。我们目前让它跟随主网络一起更新，但实际上并没有为它设计专门的优化器，也没有为它设置特定的梯度清理逻辑。这意味着它通常处于随机初始化附近，作用更多是结构性的，而不是学习性的。这也是准确率无法提升的原因之一。第三个问题是阈值的设置过于激进。我们在注意力代理里采用了一个基于正则强度的阈值策略，结果在默认配置下，这个阈值几乎等于零，因此注意力总是把类内方差视作“风险”，每一步都在促使特征向平均值靠拢。这虽然提升了鲁棒性，却让分类变得异常困难。最后，还有一个我们马上要处理的现实挑战，那就是如何把特征合理地拆解成 Token。当前的 Slot Attention 其实是在一个 token 上做循环，这显然无法发挥它的优势。我们需要深入探索怎样把空间信息重新组织成序列，让 slot 真正承担起“汇聚共性”的角色。  

面对这些问题，我已经规划好了接下来的调整思路。最首要的是控制特征的形态。我们准备在注意力之前加入一个精心设计的压缩模块，比如通过轻量的线性层或者一层简单的卷积，把特征维度压缩到一个适合注意力操作的范围。这样做可以大幅降低参数量，同时减少梯度中的噪声。其次，我们要决定注意力模块的训练策略。如果我们希望它真正学会判别条件熵，那么它就应该拥有自己的优化器和学习率，同时在每个训练步骤中都能得到清晰的梯度信号。如果我们暂时更在意分类性能，则可以考虑将注意力冻结，让它先作为一个固定的特征重排模块存在，等主网络站稳脚跟之后，再开放训练权限。至于阈值，我们也会重新设计，让它更贴近统计意义上的合理范围，让模型有机会把注意力放在真正异常的样本上，而不是每一类都一刀切地压制。  

除此之外，我还打算保留 GMM 作为对照实验。虽然我们已经在主分支中完全关闭了 GMM，但在调参阶段仍然需要一个参考系，帮我们辨别注意力替换带来的收益与代价。这意味着我们会在代码里加一个开关，让实验人员可以轻松地切换到 GMM 模式，以便记录两种方案在准确率、鲁棒性、训练速度上的差异。只有在量化了这些差异之后，我们才能真正评估注意力替换的价值。  

总的来说，这几个月我围绕着“用注意力重新定义条件熵”做了全方位的工作，从宏观的体系搭建到微观的数值调和，从工程的环境清理到实验流程的重构，所有的努力都是为了让模型既能守住隐私，又不过度牺牲性能。我相信这条路是值得走下去的，虽然当下我们遇到了准确率瓶颈，但这本身也是一个持续优化的过程。下一步的工作就是在注意力的规模、训练策略、阈值设计以及 Token 化上反复迭代，逐步把这个代理打磨成既稳定又高效的组件。如果一切顺利，我希望在不远的将来，用注意力代理作为核心的 CEM 体系能够同时给出“强鲁棒性”和“高准确率”两份答卷，也为我们团队在隐私学习方向上迈出一大步。  
